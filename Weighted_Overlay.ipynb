{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6095e505-b082-48f3-855d-a557bd3dd91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Weighted Overlay Analysis ---\n",
      "Master grid defined by 'Slope_Suitability.tif' with shape: (3601, 3601)\n",
      "Processing factor: 'slope' with weight: 0.50\n",
      "Processing factor: 'distance' with weight: 0.30\n",
      "Processing factor: 'ndvi' with weight: 0.20\n",
      "\n",
      "Writing final suitability map to: C:/Users/Lenovo/Documents/Dam_Suitability_Analysis/DATA/Final_Dam_Suitability.tif\n",
      "\n",
      "Successfully created the final suitability map!\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import rasterio\n",
    "# from rasterio.enums import Resampling\n",
    "# import numpy as np\n",
    "\n",
    "# def weighted_overlay(output_raster_path, factor_rasters, weights, nodata_val=-9999):\n",
    "#     \"\"\"\n",
    "#     Performs a weighted overlay on multiple factor rasters, ensuring they are\n",
    "#     resampled to a common grid to prevent shape mismatch errors.\n",
    "\n",
    "#     Args:\n",
    "#         output_raster_path (str): Path to save the final suitability raster.\n",
    "#         factor_rasters (dict): A dictionary where keys are factor names and values\n",
    "#                                are the paths to the corresponding suitability raster files.\n",
    "#         weights (dict): A dictionary where keys are factor names and values are\n",
    "#                         their weights (should sum to 1.0).\n",
    "#         nodata_val (int): The NoData value for the output raster.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n--- Starting Weighted Overlay Analysis ---\")\n",
    "\n",
    "#     try:\n",
    "#         # --- Step 1: Open the first raster to define the master grid ---\n",
    "#         # All other rasters will be conformed to the shape and transform of this raster.\n",
    "#         first_factor_name = list(factor_rasters.keys())[0]\n",
    "#         master_raster_path = factor_rasters[first_factor_name]\n",
    "        \n",
    "#         if not os.path.exists(master_raster_path):\n",
    "#             print(f\"!!! Error: Master grid file not found at '{master_raster_path}'. Cannot proceed.\")\n",
    "#             return\n",
    "\n",
    "#         with rasterio.open(master_raster_path) as src:\n",
    "#             master_meta = src.meta.copy()\n",
    "#             master_shape = src.shape\n",
    "            \n",
    "#             print(f\"Master grid defined by '{os.path.basename(master_raster_path)}' with shape: {master_shape}\")\n",
    "\n",
    "#             # Initialize the final weighted sum array with zeros\n",
    "#             weighted_sum = np.zeros(master_shape, dtype=np.float32)\n",
    "#             # Create a mask to keep track of NoData pixels across all layers\n",
    "#             final_nodata_mask = np.full(master_shape, False, dtype=bool)\n",
    "\n",
    "#         # --- Step 2: Iterate through each factor raster ---\n",
    "#         for factor_name, raster_path in factor_rasters.items():\n",
    "#             if not os.path.exists(raster_path):\n",
    "#                 print(f\"!!! Error: Input file not found at '{raster_path}'. Skipping this factor.\")\n",
    "#                 continue\n",
    "\n",
    "#             weight = weights[factor_name]\n",
    "#             print(f\"Processing factor: '{factor_name}' with weight: {weight:.2f}\")\n",
    "\n",
    "#             with rasterio.open(raster_path) as src:\n",
    "#                 # Read the data, resampling it on-the-fly to match the master grid's shape.\n",
    "#                 # This is the key step that solves the broadcasting error.\n",
    "#                 factor_data = src.read(\n",
    "#                     1,\n",
    "#                     out_shape=master_shape,\n",
    "#                     resampling=Resampling.bilinear # Use bilinear for continuous-like suitability scores\n",
    "#                 ).astype(np.float32)\n",
    "\n",
    "#                 input_nodata_val = src.nodata\n",
    "                \n",
    "#                 # Create a mask for NoData values AFTER resampling\n",
    "#                 nodata_mask = (factor_data == input_nodata_val)\n",
    "#                 final_nodata_mask = final_nodata_mask | nodata_mask\n",
    "                \n",
    "#                 # Set NoData pixels to 0 for the calculation so they don't affect the sum\n",
    "#                 factor_data[nodata_mask] = 0\n",
    "                \n",
    "#                 # Apply the weight and add to the total weighted sum\n",
    "#                 weighted_sum += (factor_data * weight)\n",
    "        \n",
    "#         # --- Step 3: Finalize the suitability map ---\n",
    "#         # Where any input layer had NoData, set the final output to NoData\n",
    "#         weighted_sum[final_nodata_mask] = nodata_val\n",
    "        \n",
    "#         # Update metadata for the final output file using the master grid's metadata\n",
    "#         master_meta.update(\n",
    "#             dtype=rasterio.float32, # The result is a float\n",
    "#             count=1,\n",
    "#             nodata=nodata_val,\n",
    "#             compress='lzw'\n",
    "#         )\n",
    "\n",
    "#         print(f\"\\nWriting final suitability map to: {output_raster_path}\")\n",
    "#         with rasterio.open(output_raster_path, 'w', **master_meta) as dst:\n",
    "#             dst.write(weighted_sum, 1)\n",
    "\n",
    "#         print(f\"\\nSuccessfully created the final suitability map!\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred during the weighted overlay: {e}\")\n",
    "\n",
    "# # --- MAIN SCRIPT EXECUTION ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # --- USER: VERIFY YOUR INPUTS AND WEIGHTS HERE ---\n",
    "\n",
    "#     # 1. Define the paths to your three reclassified suitability rasters\n",
    "#     suitability_layers_dir = \"C:/Users/Lenovo/Documents/Dam_Suitability_Analysis/DATA\"\n",
    "    \n",
    "#     factor_raster_paths = {\n",
    "#         \"slope\": os.path.join(suitability_layers_dir, \"Slope_Suitability.tif\"),\n",
    "#         \"distance\": os.path.join(suitability_layers_dir, \"Distance_Suitability.tif\"),\n",
    "#         \"ndvi\": os.path.join(suitability_layers_dir, \"NDVI_Suitability.tif\")\n",
    "#     }\n",
    "\n",
    "#     # 2. Define the weights for each factor. These MUST sum to 1.0.\n",
    "#     factor_weights = {\n",
    "#         \"slope\": 0.50,\n",
    "#         \"distance\": 0.30,\n",
    "#         \"ndvi\": 0.20\n",
    "#     }\n",
    "    \n",
    "#     if not np.isclose(sum(factor_weights.values()), 1.0):\n",
    "#         raise ValueError(f\"Weights must sum to 1.0, but they sum to {sum(factor_weights.values())}\")\n",
    "\n",
    "#     # 3. Define the path for the final output map\n",
    "#     final_output_path = \"C:/Users/Lenovo/Documents/Dam_Suitability_Analysis/DATA/Final_Dam_Suitability.tif\"\n",
    "    \n",
    "#     # --- END OF USER SETTINGS ---\n",
    "\n",
    "#     weighted_overlay(final_output_path, factor_raster_paths, factor_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74789db7-b4b4-40e5-8983-80585162eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Weighted Overlay Analysis ---\n",
      "Master grid defined by 'Slope_Suitability.tif' with shape: (3601, 3601)\n",
      "Processing factor: 'slope' with weight: 0.20\n",
      "Processing factor: 'distance' with weight: 0.15\n",
      "Processing factor: 'ndvi' with weight: 0.05\n",
      "Processing factor: 'depression' with weight: 0.30\n",
      "Processing factor: 'flow_accumulation' with weight: 0.30\n",
      "\n",
      "Writing final suitability map to: C:/Users/Lenovo/Documents/Dam_Suitability_Analysis/Data/Processed_Rasters/Final_Dam_Suitability.tif\n",
      "\n",
      "Successfully created the final suitability map!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "import numpy as np\n",
    "\n",
    "def weighted_overlay(output_raster_path, factor_rasters, weights, nodata_val=-9999):\n",
    "    \"\"\"\n",
    "    Performs a weighted overlay on multiple factor rasters, ensuring they are\n",
    "    resampled to a common grid to prevent shape mismatch errors.\n",
    "\n",
    "    Args:\n",
    "        output_raster_path (str): Path to save the final suitability raster.\n",
    "        factor_rasters (dict): A dictionary where keys are factor names and values\n",
    "                               are the paths to the corresponding suitability raster files.\n",
    "        weights (dict): A dictionary where keys are factor names and values are\n",
    "                        their weights (should sum to 1.0).\n",
    "        nodata_val (int): The NoData value for the output raster.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Weighted Overlay Analysis ---\")\n",
    "\n",
    "    try:\n",
    "        # --- Step 1: Open the first raster to define the master grid ---\n",
    "        # All other rasters will be conformed to the shape and transform of this raster.\n",
    "        first_factor_name = list(factor_rasters.keys())[0]\n",
    "        master_raster_path = factor_rasters[first_factor_name]\n",
    "        \n",
    "        if not os.path.exists(master_raster_path):\n",
    "            print(f\"!!! Error: Master grid file not found at '{master_raster_path}'. Cannot proceed.\")\n",
    "            return\n",
    "\n",
    "        with rasterio.open(master_raster_path) as src:\n",
    "            master_meta = src.meta.copy()\n",
    "            master_shape = src.shape\n",
    "            \n",
    "            print(f\"Master grid defined by '{os.path.basename(master_raster_path)}' with shape: {master_shape}\")\n",
    "\n",
    "            # Initialize the final weighted sum array with zeros\n",
    "            weighted_sum = np.zeros(master_shape, dtype=np.float32)\n",
    "            # Create a mask to keep track of NoData pixels across all layers\n",
    "            final_nodata_mask = np.full(master_shape, False, dtype=bool)\n",
    "\n",
    "        # --- Step 2: Iterate through each factor raster ---\n",
    "        for factor_name, raster_path in factor_rasters.items():\n",
    "            if not os.path.exists(raster_path):\n",
    "                print(f\"!!! Error: Input file not found at '{raster_path}'. Skipping this factor.\")\n",
    "                continue\n",
    "\n",
    "            weight = weights[factor_name]\n",
    "            print(f\"Processing factor: '{factor_name}' with weight: {weight:.2f}\")\n",
    "\n",
    "            with rasterio.open(raster_path) as src:\n",
    "                # Read the data, resampling it on-the-fly to match the master grid's shape.\n",
    "                # This is the key step that solves the broadcasting error.\n",
    "                factor_data = src.read(\n",
    "                    1,\n",
    "                    out_shape=master_shape,\n",
    "                    resampling=Resampling.bilinear # Use bilinear for continuous-like suitability scores\n",
    "                ).astype(np.float32)\n",
    "\n",
    "                input_nodata_val = src.nodata\n",
    "                \n",
    "                # Create a mask for NoData values AFTER resampling\n",
    "                nodata_mask = (factor_data == input_nodata_val)\n",
    "                final_nodata_mask = final_nodata_mask | nodata_mask\n",
    "                \n",
    "                # Set NoData pixels to 0 for the calculation so they don't affect the sum\n",
    "                factor_data[nodata_mask] = 0\n",
    "                \n",
    "                # Apply the weight and add to the total weighted sum\n",
    "                weighted_sum += (factor_data * weight)\n",
    "        \n",
    "        # --- Step 3: Finalize the suitability map ---\n",
    "        # Where any input layer had NoData, set the final output to NoData\n",
    "        weighted_sum[final_nodata_mask] = nodata_val\n",
    "        \n",
    "        # Update metadata for the final output file using the master grid's metadata\n",
    "        master_meta.update(\n",
    "            dtype=rasterio.float32, # The result is a float\n",
    "            count=1,\n",
    "            nodata=nodata_val,\n",
    "            compress='lzw'\n",
    "        )\n",
    "\n",
    "        print(f\"\\nWriting final suitability map to: {output_raster_path}\")\n",
    "        with rasterio.open(output_raster_path, 'w', **master_meta) as dst:\n",
    "            dst.write(weighted_sum, 1)\n",
    "\n",
    "        print(f\"\\nSuccessfully created the final suitability map!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the weighted overlay: {e}\")\n",
    "\n",
    "# --- MAIN SCRIPT EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- USER: VERIFY YOUR INPUTS AND WEIGHTS HERE ---\n",
    "\n",
    "    # 1. Define the path to your Suitability_Layers folder\n",
    "    # This path should point to your Dam_Suitability_Analysis/Data/Processed_Rasters/Suitability_Layers/\n",
    "    suitability_layers_dir = \"C:/Users/Lenovo/Documents/Dam_Suitability_Analysis/Data/Processed_Rasters\"\n",
    "    \n",
    "    factor_raster_paths = {\n",
    "        \"slope\": os.path.join(suitability_layers_dir, \"Slope_Suitability.tif\"),\n",
    "        \"distance\": os.path.join(suitability_layers_dir, \"Distance_Suitability.tif\"),\n",
    "        \"ndvi\": os.path.join(suitability_layers_dir, \"NDVI_Suitability.tif\"),\n",
    "        \"depression\": os.path.join(suitability_layers_dir, \"Depression_Suitability.tif\"),\n",
    "        \"flow_accumulation\": os.path.join(suitability_layers_dir, \"Flow_Accumulation_Suitability.tif\") # ADDED THIS LINE\n",
    "    }\n",
    "\n",
    "    # 2. Define the weights for each factor. These MUST sum to 1.0.\n",
    "    # Adjust these weights based on the importance you assign to each factor.\n",
    "    # Example weights (ensure they sum to 1.0):\n",
    "    factor_weights = {\n",
    "        \"slope\": 0.20,      # Reduced from 0.50\n",
    "        \"distance\": 0.15,   # Reduced from 0.30\n",
    "        \"ndvi\": 0.05,       # Reduced from 0.20\n",
    "        \"depression\": 0.30,  # Reduced from 0.40\n",
    "        \"flow_accumulation\": 0.30 # New, significant weight\n",
    "    }\n",
    "    \n",
    "    if not np.isclose(sum(factor_weights.values()), 1.0):\n",
    "        raise ValueError(f\"Weights must sum to 1.0, but they sum to {sum(factor_weights.values())}\")\n",
    "\n",
    "    # 3. Define the path for the final output map\n",
    "    # This path will save the final output in your Processed_Rasters folder\n",
    "    final_output_path = \"C:/Users/Lenovo/Documents/Dam_Suitability_Analysis/Data/Processed_Rasters/Final_Dam_Suitability.tif\"\n",
    "    \n",
    "    # --- END OF USER SETTINGS ---\n",
    "\n",
    "    weighted_overlay(final_output_path, factor_raster_paths, factor_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c61dc-470f-4597-845c-c04860b0c4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
